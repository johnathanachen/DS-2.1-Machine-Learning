{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib\n",
    "import pandas\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It involves removing the mean from each feature so that it is centered on zero. Mean removal helps in removing any bias from the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.array([[3, -1.5, 3, -6.4], [0, 3, -1.3, 4.1], [1, 2.3, -2.9, -4.3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean =  [ 5.55111512e-17 -3.70074342e-17  0.00000000e+00 -1.85037171e-17]\n",
      "Std deviation =  [1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "data_standardized = preprocessing.scale(input_data)\n",
    "print(\"\\nMean = \", data_standardized.mean(axis = 0))\n",
    "print(\"Std deviation = \", data_standardized.std(axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values of every feature in a data point can vary between random values. So, it is important to scale them so that this matches specified rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Min max scaled data =  [[1.         0.         1.         0.        ]\n",
      " [0.         1.         0.27118644 1.        ]\n",
      " [0.33333333 0.84444444 0.         0.2       ]]\n"
     ]
    }
   ],
   "source": [
    "data_scaler = preprocessing.MinMaxScaler(feature_range = (0, 1))\n",
    "data_scaled = data_scaler.fit_transform(input_data)\n",
    "print(\"\\nMin max scaled data = \", data_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization involves adjusting the values in the feature vector so as to measure them on a common scale. Here, the values of a feature vector are adjusted so that they sum up to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L1 normalized data =  [[ 0.21582734 -0.10791367  0.21582734 -0.46043165]\n",
      " [ 0.          0.35714286 -0.1547619   0.48809524]\n",
      " [ 0.0952381   0.21904762 -0.27619048 -0.40952381]]\n"
     ]
    }
   ],
   "source": [
    "data_normalized = preprocessing.normalize(input_data, norm  = 'l1')\n",
    "print(\"\\nL1 normalized data = \", data_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may be required to deal with numerical values that are few and scattered, and you may not need to store these values. In such situations you can use One Hot Encoding technique.\n",
    "\n",
    "If the number of distinct values is k, it will transform the feature into a k-dimensional vector where only one value is 1 and all other values are 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoded vector = [[0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "encoder = preprocessing.OneHotEncoder()\n",
    "encoder.fit([  [0, 2, 1, 12], \n",
    "               [1, 3, 5, 3], \n",
    "               [2, 3, 2, 12], \n",
    "               [1, 2, 4, 3]\n",
    "])\n",
    "encoded_vector = encoder.transform([[2, 3, 5, 3]]).toarray()\n",
    "print(\"\\nEncoded vector =\", encoded_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
